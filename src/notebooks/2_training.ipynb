{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case of problems or questions, please first check the list of [Frequently Asked Questions (FAQ)](https://stardist.net/docs/faq.html).**\n",
    "\n",
    "Please shutdown all other training/prediction notebooks before running this notebook (as those might occupy the GPU memory otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:05:49.220413600Z",
     "start_time": "2025-01-01T16:05:43.021124400Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We assume that data has already been downloaded via notebook [1_data.ipynb](1_data.ipynb).  \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Training data (for input `X` with associated label masks `Y`) can be provided via lists of numpy arrays, where each image can have a different size. Alternatively, a single numpy array can also be used if all images have the same size.  \n",
    "Input images can either be two-dimensional (single-channel) or three-dimensional (multi-channel) arrays, where the channel axis comes last. Label images need to be integer-valued.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:05:49.361612700Z",
     "start_time": "2025-01-01T16:05:49.224416700Z"
    }
   },
   "outputs": [],
   "source": [
    "X_paths = sorted(glob('F:/Cell Detection Visual Data/Data/BCCD Dataset with mask/train/patches_scaled_4/images/*.png'))\n",
    "Y_paths = sorted(glob('F:/Cell Detection Visual Data/Data/BCCD Dataset with mask/train/patches_scaled_4/masks/*.png'))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X_paths,Y_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:05:59.278567700Z",
     "start_time": "2025-01-01T16:05:49.364619800Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "X = list(map(lambda path: cv2.cvtColor(cv2.imread(path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB), X_paths))\n",
    "Y = list(map(lambda path: cv2.imread(path, cv2.IMREAD_GRAYSCALE), Y_paths))\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize images and fill small label holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:06:14.397961700Z",
     "start_time": "2025-01-01T16:05:59.282567900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing image channels independently.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 697/4676 [00:03<00:16, 236.03it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNormalizing image channels \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjointly\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m axis_norm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01min\u001B[39;00m axis_norm \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindependently\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m     10\u001B[0m     sys\u001B[38;5;241m.\u001B[39mstdout\u001B[38;5;241m.\u001B[39mflush()\n\u001B[1;32m---> 12\u001B[0m X \u001B[38;5;241m=\u001B[39m [normalize(x,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m99.8\u001B[39m,axis\u001B[38;5;241m=\u001B[39maxis_norm) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m tqdm(X)]\n\u001B[0;32m     13\u001B[0m Y \u001B[38;5;241m=\u001B[39m [fill_label_holes(y) \u001B[38;5;28;01mfor\u001B[39;00m y \u001B[38;5;129;01min\u001B[39;00m tqdm(Y)]\n",
      "Cell \u001B[1;32mIn[4], line 12\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNormalizing image channels \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjointly\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m axis_norm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01min\u001B[39;00m axis_norm \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindependently\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m     10\u001B[0m     sys\u001B[38;5;241m.\u001B[39mstdout\u001B[38;5;241m.\u001B[39mflush()\n\u001B[1;32m---> 12\u001B[0m X \u001B[38;5;241m=\u001B[39m [\u001B[43mnormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m99.8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis_norm\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m tqdm(X)]\n\u001B[0;32m     13\u001B[0m Y \u001B[38;5;241m=\u001B[39m [fill_label_holes(y) \u001B[38;5;28;01mfor\u001B[39;00m y \u001B[38;5;129;01min\u001B[39;00m tqdm(Y)]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\UnsupervisedCellDetection\\lib\\site-packages\\csbdeep\\utils\\utils.py:53\u001B[0m, in \u001B[0;36mnormalize\u001B[1;34m(x, pmin, pmax, axis, clip, eps, dtype)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Percentile-based image normalization.\"\"\"\u001B[39;00m\n\u001B[0;32m     52\u001B[0m mi \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mpercentile(x,pmin,axis\u001B[38;5;241m=\u001B[39maxis,keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 53\u001B[0m ma \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpercentile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpmax\u001B[49m\u001B[43m,\u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m normalize_mi_ma(x, mi, ma, clip\u001B[38;5;241m=\u001B[39mclip, eps\u001B[38;5;241m=\u001B[39meps, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\UnsupervisedCellDetection\\lib\\site-packages\\numpy\\lib\\function_base.py:4283\u001B[0m, in \u001B[0;36mpercentile\u001B[1;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001B[0m\n\u001B[0;32m   4281\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _quantile_is_valid(q):\n\u001B[0;32m   4282\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPercentiles must be in the range [0, 100]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 4283\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_quantile_unchecked\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4284\u001B[0m \u001B[43m    \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverwrite_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\UnsupervisedCellDetection\\lib\\site-packages\\numpy\\lib\\function_base.py:4555\u001B[0m, in \u001B[0;36m_quantile_unchecked\u001B[1;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001B[0m\n\u001B[0;32m   4547\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_quantile_unchecked\u001B[39m(a,\n\u001B[0;32m   4548\u001B[0m                         q,\n\u001B[0;32m   4549\u001B[0m                         axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4552\u001B[0m                         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinear\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   4553\u001B[0m                         keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m   4554\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001B[39;00m\n\u001B[1;32m-> 4555\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_ureduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4556\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_quantile_ureduce_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4557\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4558\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4559\u001B[0m \u001B[43m                    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4560\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4561\u001B[0m \u001B[43m                    \u001B[49m\u001B[43moverwrite_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverwrite_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4562\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\UnsupervisedCellDetection\\lib\\site-packages\\numpy\\lib\\function_base.py:3823\u001B[0m, in \u001B[0;36m_ureduce\u001B[1;34m(a, func, keepdims, **kwargs)\u001B[0m\n\u001B[0;32m   3820\u001B[0m             index_out \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m0\u001B[39m, ) \u001B[38;5;241m*\u001B[39m nd\n\u001B[0;32m   3821\u001B[0m             kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mout\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m out[(\u001B[38;5;28mEllipsis\u001B[39m, ) \u001B[38;5;241m+\u001B[39m index_out]\n\u001B[1;32m-> 3823\u001B[0m r \u001B[38;5;241m=\u001B[39m func(a, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   3825\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3826\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\UnsupervisedCellDetection\\lib\\site-packages\\numpy\\lib\\function_base.py:4722\u001B[0m, in \u001B[0;36m_quantile_ureduce_func\u001B[1;34m(a, q, axis, out, overwrite_input, method)\u001B[0m\n\u001B[0;32m   4720\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   4721\u001B[0m         arr \u001B[38;5;241m=\u001B[39m a\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m-> 4722\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43m_quantile\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4723\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mquantiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4724\u001B[0m \u001B[43m                   \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4725\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4726\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4727\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\UnsupervisedCellDetection\\lib\\site-packages\\numpy\\lib\\function_base.py:4824\u001B[0m, in \u001B[0;36m_quantile\u001B[1;34m(arr, quantiles, axis, method, out)\u001B[0m\n\u001B[0;32m   4820\u001B[0m previous_indexes, next_indexes \u001B[38;5;241m=\u001B[39m _get_indexes(arr,\n\u001B[0;32m   4821\u001B[0m                                               virtual_indexes,\n\u001B[0;32m   4822\u001B[0m                                               values_count)\n\u001B[0;32m   4823\u001B[0m \u001B[38;5;66;03m# --- Sorting\u001B[39;00m\n\u001B[1;32m-> 4824\u001B[0m \u001B[43marr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpartition\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4825\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4826\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mprevious_indexes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4827\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mnext_indexes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4828\u001B[0m \u001B[43m                              \u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4829\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4830\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m supports_nans:\n\u001B[0;32m   4831\u001B[0m     slices_having_nans \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39misnan(arr[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m])\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "X = list(map(lambda path: cv2.cvtColor(cv2.imread(path, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB), X_paths))\n",
    "Y = list(map(lambda path: cv2.imread(path, cv2.IMREAD_GRAYSCALE), Y_paths))\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]\n",
    "\n",
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.329946Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data consists of pairs of input image and label instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.331946200Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_img_label(img, lbl, img_title=\"image\", lbl_title=\"label\", **kwargs):\n",
    "    fig, (ai,al) = plt.subplots(1,2, figsize=(12,5), gridspec_kw=dict(width_ratios=(1.25,1)))\n",
    "    im = ai.imshow(img, cmap='gray', clim=(0,1))\n",
    "    ai.set_title(img_title)    \n",
    "    fig.colorbar(im, ax=ai)\n",
    "    al.imshow(lbl, cmap=lbl_cmap)\n",
    "    al.set_title(lbl_title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.333946Z"
    }
   },
   "outputs": [],
   "source": [
    "i = min(9, len(X)-1)\n",
    "img, lbl = X[i], Y[i]\n",
    "assert img.ndim in (2,3)\n",
    "img = img if (img.ndim==2 or img.shape[-1]==3) else img[...,0]\n",
    "plot_img_label(img,lbl)\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "A `StarDist2D` model is specified via a `Config2D` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.336946300Z"
    }
   },
   "outputs": [],
   "source": [
    "print(Config2D.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.339945900Z"
    }
   },
   "outputs": [],
   "source": [
    "# 32 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 64\n",
    "\n",
    "# Use OpenCL-based computations for data generator during training (requires 'gputools')\n",
    "use_gpu = False and gputools_available()\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = (2,2)\n",
    "\n",
    "conf = Config2D (\n",
    "    n_rays       = n_rays,\n",
    "    grid         = grid,\n",
    "    use_gpu      = use_gpu,\n",
    "    n_channel_in = n_channel,\n",
    ")\n",
    "print(conf)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.341946100Z"
    }
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    from csbdeep.utils.tf import limit_gpu_memory\n",
    "    # adjust as necessary: limit GPU memory to be used by TensorFlow to leave some to OpenCL-based computations\n",
    "    limit_gpu_memory(0.8)\n",
    "    # alternatively, try this:\n",
    "    # limit_gpu_memory(None, allow_growth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The trained `StarDist2D` model will *not* predict completed shapes for partially visible objects at the image boundary if `train_shape_completion=False` (which is the default option)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.344946400Z"
    }
   },
   "outputs": [],
   "source": [
    "model = StarDist2D(conf, name='stardist', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the neural network has a large enough field of view to see up to the boundary of most objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.347946200Z"
    }
   },
   "outputs": [],
   "source": [
    "median_size = calculate_extents(list(Y), np.median)\n",
    "fov = np.array(model._axes_tile_overlap('YX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define a function/callable that applies augmentation to each batch of the data generator.  \n",
    "We here use an `augmenter` that applies random rotations, flips, and intensity changes, which are typically sensible for (2D) microscopy images (but you can disable augmentation by setting `augmenter = None`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.349946Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_fliprot(img, mask): \n",
    "    assert img.ndim >= mask.ndim\n",
    "    axes = tuple(range(mask.ndim))\n",
    "    perm = tuple(np.random.permutation(axes))\n",
    "    img = img.transpose(perm + tuple(range(mask.ndim, img.ndim))) \n",
    "    mask = mask.transpose(perm) \n",
    "    for ax in axes: \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=ax)\n",
    "            mask = np.flip(mask, axis=ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def augmenter(x, y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    x, y = random_fliprot(x, y)\n",
    "    x = random_intensity_change(x)\n",
    "    # add some gaussian noise\n",
    "    sig = 0.02*np.random.uniform(0,1)\n",
    "    x = x + sig*np.random.normal(0,1,x.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.351945800Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot some augmented examples\n",
    "img, lbl = X[0],Y[0]\n",
    "plot_img_label(img, lbl)\n",
    "for _ in range(3):\n",
    "    img_aug, lbl_aug = augmenter(img,lbl)\n",
    "    plot_img_label(img_aug, lbl_aug, img_title=\"image augmented\", lbl_title=\"label augmented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend to monitor the progress during training with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard). You can start it in the shell from the current working directory like this:\n",
    "\n",
    "    $ tensorboard --logdir=.\n",
    "\n",
    "Then connect to [http://localhost:6006/](http://localhost:6006/) with your browser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.353946100Z"
    }
   },
   "outputs": [],
   "source": [
    "quick_demo = True\n",
    "\n",
    "if quick_demo:\n",
    "    print (\n",
    "        \"NOTE: This is only for a quick demonstration!\\n\"\n",
    "        \"      Please set the variable 'quick_demo = False' for proper (long) training.\",\n",
    "        file=sys.stderr, flush=True\n",
    "    )\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter,\n",
    "                epochs=2, steps_per_epoch=10)\n",
    "\n",
    "    print(\"====> Stopping training and loading previously trained demo model from disk.\", file=sys.stderr, flush=True)\n",
    "    model = StarDist2D.from_pretrained('2D_demo')\n",
    "else:\n",
    "    model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter)\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the default values for the probability and non-maximum suppression thresholds already yield good results in many cases, we still recommend to adapt the thresholds to your data. The optimized threshold values are saved to disk and will be automatically loaded with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.355946600Z"
    }
   },
   "outputs": [],
   "source": [
    "if quick_demo:\n",
    "    model.optimize_thresholds(X_val[:2], Y_val[:2])\n",
    "else:\n",
    "    model.optimize_thresholds(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Detection Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the losses and metrics during training, we can also quantitatively evaluate the actual detection/segmentation performance on the validation data by considering objects in the ground truth to be correctly matched if there are predicted objects with overlap (here [intersection over union (IoU)](https://en.wikipedia.org/wiki/Jaccard_index)) beyond a chosen IoU threshold $\\tau$.\n",
    "\n",
    "The corresponding matching statistics (average overlap, accuracy, recall, precision, etc.) are typically of greater practical relevance than the losses/metrics computed during training (but harder to formulate as a loss function). \n",
    "The value of $\\tau$ can be between 0 (even slightly overlapping objects count as correctly predicted) and 1 (only pixel-perfectly overlapping objects count) and which $\\tau$ to use depends on the needed segmentation precision/application.\n",
    "\n",
    "Please see `help(matching)` for definitions of the abbreviations used in the evaluation below and see the Wikipedia page on [Sensitivity and specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.357945700Z"
    }
   },
   "outputs": [],
   "source": [
    "# help(matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First predict the labels for all validation images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.359946500Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_val_pred = [model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)[0]\n",
    "              for x in tqdm(X_val)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a GT/prediction example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.361946700Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_img_label(X_val[0],Y_val[0], lbl_title=\"label GT\")\n",
    "plot_img_label(X_val[0],Y_val_pred[0], lbl_title=\"label Pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose several IoU thresholds $\\tau$ that might be of interest and for each compute matching statistics for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.362946200Z"
    }
   },
   "outputs": [],
   "source": [
    "taus = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "stats = [matching_dataset(Y_val, Y_val_pred, thresh=t, show_progress=False) for t in tqdm(taus)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Print all available matching statistics for $\\tau=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.364946Z"
    }
   },
   "outputs": [],
   "source": [
    "stats[taus.index(0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the matching statistics and the number of true/false positives/negatives as a function of the IoU threshold $\\tau$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T16:06:14.366946700Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "for m in ('precision', 'recall', 'accuracy', 'f1', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'):\n",
    "    ax1.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax1.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax1.set_ylabel('Metric value')\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "for m in ('fp', 'tp', 'fn'):\n",
    "    ax2.plot(taus, [s._asdict()[m] for s in stats], '.-', lw=2, label=m)\n",
    "ax2.set_xlabel(r'IoU threshold $\\tau$')\n",
    "ax2.set_ylabel('Number #')\n",
    "ax2.grid()\n",
    "ax2.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
